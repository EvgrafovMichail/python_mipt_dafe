{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3e1847",
   "metadata": {},
   "source": [
    "# Операции над объектами Pandas\n",
    "\n",
    "На прошлом занятии мы начали изучать библиотеку Pandas и познакомились с ее основными структурами данных: `Index`, `Series` и `DataFrame`. Очевидно, что работа с данными не ограничивается исключительно их хранением и чтением, а зачастую включается в себя применение специальных операций и функций: логических, арифметических, математических, статистических и т.д. в зависимости от задачи. Сегодня мы с вами познакомимся с функциями и методами объектов Pandas, которые позволяют эффективно обрабатывать большие объемы различных данных.\n",
    "\n",
    "**Необходимые импорты**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3623c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2625f8",
   "metadata": {},
   "source": [
    "## Векторизованные операции в стиле NumPy\n",
    "\n",
    "Pandas во многом построена на массивах NumPy, а потому значительная часть векторизованных операций из NumPy может быть использована вместе с объектами `pd.Series` и `pd.DataFrame`. Однако, при использовании этих операций с объектами `Pandas` существуют свои тонкости. Рассмотрим эти тонкости детальнее.\n",
    "\n",
    "### Сохранение индексов\n",
    "\n",
    "Объекты `pd.Series` и `pd.DataFrame` - это не просто одномерные и двумерные массивы данных. Это структуры данных с явными типизированными индексами. Этот факт учитывается во время выполнения различных операций над объектами `pd.Series` и `pd.DataFrame`.  Так при выполнении унарных операций или при применении к этим объектам арифметических функций, Pandas будет использовать индексы исходного объекта в качестве индексов результата выполнения вычислений. Благодаря этому подходу разработчики получают легкий способ обновлять столбцы датафреймов, используя результаты выполнения различных операций.\n",
    "\n",
    "Рассмотрим примеры сохранения индексов во время выполнения различных вычислений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(\n",
    "    data=np.random.normal(size=5),\n",
    "    index=list(\"ABCDE\"),\n",
    ")\n",
    "series_exp = np.exp(series)\n",
    "\n",
    "print(\n",
    "    f\"Original series:\\n{series}\",\n",
    "    f\"Series exp:\\n{series_exp}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b03bd3",
   "metadata": {},
   "source": [
    "Аналогичным образом сохранение индексов строк и индексов столбцов выполняется и для `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_amount, col_amount = 3, 4\n",
    "\n",
    "data_frame = pd.DataFrame(\n",
    "    data=np.random.normal(size=(row_amount, col_amount)),\n",
    "    index=[f\"row_{i + 1}\" for i in range(row_amount)],\n",
    "    columns=[f\"col_{i + 1}\" for i in range(col_amount)],\n",
    ")\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98156d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(data_frame * np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c763ec3",
   "metadata": {},
   "source": [
    "### Выравнивание индексов\n",
    "\n",
    "Вторая, более важная особенность выполнения операций с объектами Pandas, заключается в выравнивании индексов. Из NumPy мы знаем, что при попытке выполнениях бинарных операций с одномерными массивами `np.ndarray`, мы получим ошибку. Поскольку массивы NumPy лежат в основе библиотеки Pandas, может создастся впечатление, что похожее поведение должно быть справедливо и для объектов `pd.Series` с разными индексами. Ведь `pd.Series` - это аналог одномерного массива `np.ndarray` с явно заданным индексом, а отличия в количестве элементов массивов `np.ndarray` аналогично отличиям в индексах объектов `pd.Series`.  Однако это ложное предположение. В Pandas возможно выполнение бинарных операций над объектами `pd.Series` с разными индексами. Более того, в результате этих операций получаются вполне предсказуемые и логичные результаты. Рассмотрим пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = pd.Series(\n",
    "    {\n",
    "        \"Moscow\": 13149803,\n",
    "        \"Saint Petersburg\": 5600044,\n",
    "        \"Novosibirsk\": 1635338,\n",
    "        \"Ekaterinburg\": 1539371,\n",
    "    },\n",
    ")\n",
    "areas = pd.Series(\n",
    "    {\n",
    "        \"Kazan\": 515.8,\n",
    "        \"Ekaterinburg\": 1112,\n",
    "        \"Moscow\": 2511,\n",
    "    },\n",
    ")\n",
    "population_density = populations / areas\n",
    "\n",
    "print(f\"Population density:\\n{population_density}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f383a12",
   "metadata": {},
   "source": [
    "В данном примере мы определили `pd.Series` `populations`, в котором отражены численности населения российских городов. Также мы определили `pd.Series` `areas`, в котором отражены площади российских городов. Индексы определенных серий разные. Они имеют пересечения в виде ключей `\"Ekaterinburg\"` и `\"Moscow\"`, однако остальные ключи отличаются. Далее выполняется операция бинарного деления, чтобы определить плотность населения в российских городах. В результате выполнения мы получили объект `pd.Series`, в котором плотность населения определена только для тех значений индекса, которые присутствовали и в первой, и во второй серии. Остальным же значениям индекса соответствует странное значение `NaN`, о котором мы поговорим ниже. Однако, факт остается фактом - мы можем выполнять бинарные операции с объектами, обладающими разными индексами.\n",
    "\n",
    "Рассмотрим детальнее результат выполнения такой операции. Во-первых, видно что индекс результирующей серии является объединением значений индексов операндов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4762baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_index_united = np.all(\n",
    "    population_density.index == populations.index.union(areas.index)\n",
    ")\n",
    "\n",
    "print(f\"is index was united: {is_index_united}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538af6b5",
   "metadata": {},
   "source": [
    "Во-вторых, значения индекса результата выполнения операции отсортированы в порядке возрастания. Поскольку в данном примере в качестве значений индекса были использованы названия городов, значения результирующего индекса отсортированы в алфавитном порядке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_density.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cfbb6",
   "metadata": {},
   "source": [
    "Аналогичные результаты будут справедливы и для объектов `pd.DataFrame`. Единственное отличие будет заключать в выравнивании индексов по двум измерениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame1 = pd.DataFrame(\n",
    "    data=np.random.randint(0, 20, size=(2, 2)),\n",
    "    columns=list(\"AB\"),\n",
    ")\n",
    "data_frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8544b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame2 = pd.DataFrame(\n",
    "    data=np.random.randint(0, 10, size=(3, 3)),\n",
    "    columns=list(\"BAC\"),\n",
    ")\n",
    "data_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame1 + data_frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18659482",
   "metadata": {},
   "source": [
    "Единственный момент, который может смущать нас на данном этапе - наличие непонятного значения `NaN` в данных. При выполнении бинарных операций с объектами Pandas, мы можем предотвратить появление этого значения в результате. Чтобы это сделать, нам придется воспользоваться другой формой бинарных операций - бинарными операциями в форме методов объектов `pd.Series` и `pd.DataFrame`. При использовании данной формы бинарных операций с помощью аргумента `fill_value` мы можем явно указать, какое значение стоит использовать в тех случаях, когда ключ отсутствует в одном из операндов. В этом случае результат будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43288e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame1.add(data_frame2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4c244",
   "metadata": {},
   "source": [
    "Таблица соответствия методов и бинарных операций:\n",
    "\n",
    "| Оператор Python | Метод объекта Pandas |\n",
    "|---|---|\n",
    "| + | add() |\n",
    "| - | sub(), subtract() |\n",
    "| * | mul(), multiply() |\n",
    "| / | truediv(), div(), divide() |\n",
    "| // | floordiv() |\n",
    "| % | mod() |\n",
    "| ** | pow() |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1e432",
   "metadata": {},
   "source": [
    "### Транслирование (Broadcasting)\n",
    "\n",
    "Во всех предыдущих примерах для выполнения бинарных операций мы использовали операнды одних и тех же типов данных. Однако мы можем выполнять бинарные операции с операндами различных типов данных. Например, мы можем вычитать объект типа `pd.Series` из объекта типа `pd.DataFrame`. В случае, если индексы объектов совпадают, результат будет аналогичен вычитанию одномерного массива `np.ndarray` из двумерного массива `np.ndarray`. Т.е. будет происходить транслирование одномерного объекта по уже знакомым нам правилам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230861d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_amount, col_amount = 3, 4\n",
    "\n",
    "data_frame = pd.DataFrame(\n",
    "    data=np.random.randint(0, 10, size=(row_amount, col_amount)),\n",
    "    index=[f\"row_{i + 1}\" for i in range(row_amount)],\n",
    "    columns=[f\"col_{i + 1}\" for i in range(col_amount)],\n",
    ")\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame - data_frame.loc[\"row_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b88e9f",
   "metadata": {},
   "source": [
    "По умолчанию вычитание происходит построчно. Однако далеко не всегда мы хотим выполнять операции построчно. Существуют случае, когда нам необходимо выполнить некоторую операцию по столбцам. В этом случае нам придется воспользоваться методами объектов Pandas для выполнения бинарных операций, а также указать значение аргумента `axis=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ea5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.subtract(data_frame[\"col_1\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2892dd",
   "metadata": {},
   "source": [
    "Также далеко не всегда индексы операндов могут совпадать. В этом случае будет происходить уже знакомое нам выравнивание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row_odd_columns = data_frame.iloc[0, ::2]\n",
    "\n",
    "print(\n",
    "    \"even columns values from first row:\\n\"\n",
    "    f\"{first_row_odd_columns}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a194ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame - first_row_odd_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c1a50",
   "metadata": {},
   "source": [
    "## NaN. Обработка отсутствующих данных\n",
    "\n",
    "### Что такое NaN и откуда он взялся?\n",
    "\n",
    "В предыдущих примерах мы столкнулись со значением `NaN` в наших данных. Это специальное значение, которое Pandas использует для того, чтобы помечать отсутствующие данные. `NaN` - акроним, составленный из первых букв фразы *not a number*. Давайте разберемся, как еще `NaN` может попасть в наши данные, как задать это значение самостоятельно, и как с ним работать.\n",
    "\n",
    "Часто при работе с реальными данными, нам приходится сталкиваться с неполными данными. Например, в результате некоторого статистического опроса несколько респондентов забыли заполнить графу возраста. В этом случае некоторые данные о респондентах будут неполные. Неполные данные легко представить на бумаге, но как представлять неполные данные в коде?  В Python для этих целей мы использовали объект-синглтон None. Однако при работе с NumPy использование None приводит к печальным последствиям. Рассмотрим пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1, 2, None, 4])\n",
    "\n",
    "print(\n",
    "    f\"array data:\\n{array}\",\n",
    "    f\"array dtype: {array.dtype}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1b30e",
   "metadata": {},
   "source": [
    "Из этого кода следует следующее. Если NumPy встречает в данных объект `None`, он осуществляет повышающее преобразование типов. После преобразования типов в массиве `np.ndarray` будут лежать данные типа `object`. Т.е. NumPy будет воспринимать содержимое  массива, как обычные объекты Python. Это значит, что работа с таким массивом не будет отличаться от работы с обычными списками Python. Никакая векторизация в таком случае невозможна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = \"import numpy as np\"\n",
    "template = \"np.arange(int(1e6), dtype=%s).sum()\"\n",
    "iteration_amount = 1000\n",
    "\n",
    "for dtype in [\"np.object_\", \"np.int32\"]:\n",
    "    print(f\"dtype: {dtype}\")\n",
    "    time_per_iter = timeit.timeit(\n",
    "        setup=setup,\n",
    "        stmt=template % dtype,\n",
    "        number=iteration_amount,\n",
    "    ) / iteration_amount\n",
    "    print(f\"time_taken: {time_per_iter:.4f}s;\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1f267",
   "metadata": {},
   "source": [
    "Более того, мы даже не сможем выполнять некоторые агрегирующие операции над содержимым такого массива. Из-за наличия в данных `None` мы с большой долей вероятности получим ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"array:\\n{array}\")\n",
    "sum_of_elements = array.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b67458",
   "metadata": {},
   "source": [
    "Чтобы обойти все эти ограничения, в NumPy реализовано специальное сигнальное значение `np.nan` в соответствии со стандартом IEEE. Фактически `np.nan` - это специальное число с плавающей точкой, используемое в качестве признака отсутствия данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([1, 2, np.nan, 3])\n",
    "\n",
    "print(\n",
    "    f\"array data:\\n{array}\",\n",
    "    f\"array dtype: {array.dtype}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae59c6",
   "metadata": {},
   "source": [
    "По своей природе значение `np.nan` похоже на вирус, который заражает собой любые данные, т.к. при выполнении любой операции с использованием `np.nan` результат также будет представлять собой `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdf3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"addition: {np.nan + 42}\",\n",
    "    f\"multiplication: {np.nan * 42}\",\n",
    "    f\"agregation: {array.sum()}\",\n",
    "    f\"safe agregation: {np.nansum(array)}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c3c546",
   "metadata": {},
   "source": [
    "Поскольку в основе Pandas лежит NumPy, мы можем использовать значение `np.nan`, чтобы помечать отсутствующие данные. Также разработчики Pandas добавили возможность использования `None` для того, чтобы помечать отсутствующие данные. Таким образом мы имеем два взаимозаменяемых способа задания пропущенных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cad3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([1, None, 2, np.nan])\n",
    "print(f\"series:\\n{series}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78fa90",
   "metadata": {},
   "source": [
    "Также обращаем ваше внимание, что при появлении в данных `NaN`, Pandas может произвести повышающее преобразование типов. Так, в данном примеры изначальный тип данных объекта `pd.Series` был `int32`, т.е. тип данных был целочисленный. После того, как мы пометили данные под индексом 0 как отсутствующие, Pandas произвел повышающее преобразование типов до `float64`. Это произошло, потому что `np.nan` - это число с плавающей точкой, а объект `None`, используемый для пометки отсутствующих данных, Pandas неявно преобразует в `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(np.arange(4))\n",
    "print(f\"original series:\\n{series}\", end=\"\\n\\n\")\n",
    "\n",
    "series[0] = None\n",
    "print(f\"corrupted series:\\n{series}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cedb4",
   "metadata": {},
   "source": [
    "### Выявление пустых значений\n",
    "\n",
    "Первое, что стоит сделать с полученными данными - определить, присутствуют ли в них пропуски или нет. И если пропуски присутствуют, желательно понимать, где именно. Определить положения `NaN` в данных можно с помощью метода `isnull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([1, None, 2, 3, np.nan])\n",
    "print(f\"series:\\n{series}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data_missed = series.isnull()\n",
    "print(f\"missed data mask:\\n{mask_data_missed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebcc89",
   "metadata": {},
   "source": [
    "В Pandas также определен антипод метода `isnull` - `notnull`, который позволяет определить булеву маски для данных, не являющихся `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"corrupted data:\\n{series[mask_data_missed]}\",\n",
    "    f\"correct data:\\n{series[series.notnull()]}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844fead",
   "metadata": {},
   "source": [
    "### Удаление пустых значений\n",
    "\n",
    "Установив наличие `NaN` в данных, необходимо решить, что с ними делать. Редко в каких задачах уместно оставлять пропущенные данные. Обычно от пропусков или избавляются, или пытаются их заполнить по определенным правилам. Если данных очень много, пропусков очень мало, а их заполнение нецелесообразно, может потребоваться простое удаление таких данных из Pandas объектов. Это можно сделать с помощью метода `dropna`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([1, None, 2, 3, np.nan])\n",
    "print(f\"series:\\n{series}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"correct data:\\n{series.dropna()}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de47dc1",
   "metadata": {},
   "source": [
    "В случае работы с объектом `pd.Series` удаление `NaN` довольно прямолинейно. Однако при удалении данных из `pd.DataFrame` возникают сложности. Дело в том, что мы не можем удалять из датафрейма отдельные ячейки с данными. Можно удалить только строку или столбец целиком. По умолчанию `dropna` удаляет строки, содержащие хотя бы одно значение `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(\n",
    "    data=[\n",
    "        [1, 2, np.nan],\n",
    "        [4, 5, 6],\n",
    "        [np.nan, 8, np.nan],\n",
    "    ],\n",
    "    columns=list(\"ABC\")\n",
    ")\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7faa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52079da",
   "metadata": {},
   "source": [
    "Используя аргумент `axis`, мы можем указать измерение, вдоль которого должно анализироваться наличие пропусков. В примере ниже будут удалены все столбцы, содержащие хотя бы одно значение `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e95bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.dropna(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828ef8b",
   "metadata": {},
   "source": [
    "Так же функция `dropna` позволяет настраивать стратегии удаления строк и столбцов из датафрейма. Как говорилось выше, по умолчанию для удаления строки или столбца достаточно наличия хотя бы одного значения `NaN`. Однако такая стратегия может быть не всегда уместной. Часто в нашем распоряжении не так много данных, чтобы мы могли позволить себе выбрасывать строки или столбцы только из-за наличия одного `NaN`. Именно поэтому Pandas позволяет настроить правила, в соответствии с которым будет происходить удаление строк или столбцов. Так мы можем установить минимальное число значений отличных от `NaN`, необходимое для сохранения строки или столбца в датафрейме. Сделать это можно с помощью параметра `thresh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee739b3",
   "metadata": {},
   "source": [
    "Также при необходимости мы можем удалять только те строки или столбцы, которые полностью заполнены `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.iloc[-1, 1] = np.nan\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e556e33",
   "metadata": {},
   "source": [
    "### Заполнение пустых значений\n",
    "\n",
    "Выше упоминалось, что в нашем распоряжении обычно не так много данных, чтобы мы могли позволить себе их сокращение путем удаления. Именно поэтому часто более оптимальной стратегией для обработки пропусков является заполнение, а не удаление. Заполнить пропущенные данные в Pandas можно с помощью методов `fillna`, `ffill` и `bfill`.\n",
    "\n",
    "С помощью метода `fillna` можно заполнить недостающие данные переданным значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([None, 1, 2, 3, np.nan])\n",
    "print(\n",
    "    f\"series original:\\n{series}\",\n",
    "    f\"series filled:\\n{series.fillna(0)}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190bd3b",
   "metadata": {},
   "source": [
    "`ffill` и `bfill` используют, соответственно, предшествующее и следующее значение для заполнения пропусков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"series original:\\n{series}\",\n",
    "    f\"series forward fill:\\n{series.ffill()}\",\n",
    "    f\"series backward fill:\\n{series.bfill()}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b1881",
   "metadata": {},
   "source": [
    "В случае с `DataFrame` справедливо все, сказанное выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(\n",
    "    [\n",
    "        [1, 2, np.nan],\n",
    "        [4, 5, 6],\n",
    "        [np.nan, 9, np.nan],\n",
    "    ],\n",
    "    columns=list(\"ABC\"),\n",
    ")\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7689b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4f757",
   "metadata": {},
   "source": [
    "Мы также можем использовать объект `pd.Series`, чтобы заполнять пропущенные значения в разных столбцах по-разному."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = pd.Series(\n",
    "    data=[42, 69],\n",
    "    index=list(\"AC\"),\n",
    ")\n",
    "data_frame.fillna(fill_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a01f5",
   "metadata": {},
   "source": [
    "Из-за двумерной природы объекта `pd.DataFrame` при использовании методов `ffill` и `bfill` мы можем выбирать размерность, вдоль которой будут использоваться предшествующие и следующие значения для заполнения пропусков. По умолчанию пропуски заполняются вдоль столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cebba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.ffill(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c121c30",
   "metadata": {},
   "source": [
    "## Операции агрегирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edba434",
   "metadata": {},
   "source": [
    "Объекты Pandas также поддерживают операции агрегирования. Поскольку простые операции агрегирования ничем не отличаются от соответствующих операций в NumPy, не будет заострять на них наше внимание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c570b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_data = sns.load_dataset(\"planets\")\n",
    "planets_data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd690918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"mean orbital period: {planets_data['orbital_period'].mean():.2f};\",\n",
    "    f\"first year of research: {planets_data['year'].min()};\",\n",
    "    f\"last year of research: {planets_data['year'].max()};\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271101b",
   "metadata": {},
   "source": [
    "С помощью метода `unique` возможно получение уникальных значений, хранящихся в объекте типа `pd.Series`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_data[\"method\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383a088",
   "metadata": {},
   "source": [
    "Также в Pandas реализован метод `describe`, который позволяет вычислить основные статистики числовых данных. Эта функция может быть полезна при проведении разведывательного анализа данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_data.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969f4d1",
   "metadata": {},
   "source": [
    "## Операции со строковыми данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1259f42",
   "metadata": {},
   "source": [
    "Обсуждая NumPy, мы с вами занимались исключительно работой с числовыми данными. Теперь, работая с таблицами Pandas, нам нередко будут встречаться строковые данные. Необходимо уметь эффективно обрабатывать строковые данные и уметь пользоваться векторизованными строковыми операциями. Это можно сделать, используя специальный атрибут объектов `pd.Series` и `pd.DataFrame` - `str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.Series(\n",
    "    data=[\"john\", \"Paul\", \"george\", \"RINGO\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"names:\\n{names}\",\n",
    "    f\"names corrected:\\n{names.str.capitalize()}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89eb70",
   "metadata": {},
   "source": [
    "В Pandas реализовано множество векторизованных операций для работы со строками, являющееся аналогом множества методов строк в Python. Если вы знакомы с оригинальными методами, вы без труда сможете разобраться с логикой работы аналогов в Pandas. Ниже приведем пару примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.Series(\n",
    "    data=[\n",
    "        \"John Lennon\",\n",
    "        \"Paul MacCartney\",\n",
    "        \"George Harrison\",\n",
    "        \"Ringo Starr\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"names lens:\\n{names.str.len()}\",\n",
    "    f\"correction mask:\\n{names.str.istitle()}\",\n",
    "    f\"names split:\\n{names.str.split()}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40981b65",
   "metadata": {},
   "source": [
    "Также в Pandas реализованы векторизованные операции для работы с регулярными выражениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf58fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"pattern matching:\\n{names.str.match(r'[A-Za-z]+')}\",\n",
    "    f\"pattern inclusion:\\n{names.str.contains(r'[Jj]ohn')}\",\n",
    "    f\"pattern finding:\\n{names.str.findall(r'^[^AEIOUY]*[^aeiouy]$')}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc4b6b1",
   "metadata": {},
   "source": [
    "Также реализованы операции векторизованного среза строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"explicit slice:\\n{names.str.slice(0, 3)}\",\n",
    "    f\"implicit slice:\\n{names.str[:3]}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e423a",
   "metadata": {},
   "source": [
    "## Задача 1. My heart will go on\n",
    "\n",
    "Датасет **titanic** из библиотеки `Seaborn` содержит информацию о пассажирах легендарного корабля Титаник, который затонул в 1912 году после столкновения с айсбергом. Этот набор данных часто используется для обучения и тестирования алгоритмов машинного обучения, особенно в задачах бинарной классификации (выжил / не выжил).\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "| Поле         | Тип      | Описание |\n",
    "|--------------|----------|----------|\n",
    "| `survived`   | int      | Выжил (1) или не выжил (0) |\n",
    "| `pclass`     | int      | Класс билета (1, 2, 3) |\n",
    "| `sex`        | str      | Пол (`male`/`female`) |\n",
    "| `age`        | float    | Возраст |\n",
    "| `sibsp`      | int      | Количество братьев/сестёр/супругов на борту |\n",
    "| `parch`      | int      | Количество родителей/детей на борту |\n",
    "| `fare`       | float    | Стоимость билета |\n",
    "| `embarked`   | str      | Порт посадки (`C`=Cherbourg, `Q`=Queenstown, `S`=Southampton) |\n",
    "| `class`      | str      | Класс билета (`First`, `Second`, `Third`) |\n",
    "| `who`        | str      | Категория: `man`, `woman` или `child` |\n",
    "| `adult_male` | bool     | Является ли взрослым мужчиной |\n",
    "| `deck`       | str      | Палуба |\n",
    "| `embark_town`| str      | Название порта посадки |\n",
    "| `alive`      | str      | Выжил (`yes`/`no`) |\n",
    "| `alone`      | bool     | Путешествовал один |\n",
    "\n",
    "**Загрузка датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b00711",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = sns.load_dataset(\"titanic\")\n",
    "titanic_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf1941",
   "metadata": {},
   "source": [
    "**Задача**\n",
    "\n",
    "Ниже описаны 10 небольших заданий, которые вам необходимо решить.\n",
    "\n",
    "**Подсказка**:\n",
    "\n",
    "В некоторых заданиях вам может быть полезен метод `value_counts`.\n",
    "\n",
    "### Часть 1\n",
    "\n",
    "Определите число пропущенных данных для каждого столбца таблицы `titanic_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62022b",
   "metadata": {},
   "source": [
    "### Часть 2\n",
    "\n",
    "Удалите все столбцы, количество пропусков в которых превышает половину количества строк в таблице.\n",
    "\n",
    "После того, как вы удалите все столбцы, нарушающие описанное условие, удалите все строки, количество элементов в которых превышает половину количества столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e458447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970caffe",
   "metadata": {},
   "source": [
    "### Часть 3\n",
    "\n",
    "Если вы сделали все правильно, больше всего пропусков должно остаться в столбце `\"age\"` - 177. Их необходимо заполнить. Заполним пропуски следующим образом:\n",
    "- Если значение столбца `\"who\"=\"man\"`, пропуск необходимо заполнить медианным значением известных возрастов мужчин, округленным до ближайшего целого числа;\n",
    "- Если значение столбца `\"who\"=\"woman\"`, пропуск необходимо заполнить медианным значением известных возрастов женщин, округленным до ближайшего целого числа;\n",
    "- Если значение столбца `\"who\"=\"child\"`, пропуск необходимо заполнить медианным значением известных возрастов детей, округленным до ближайшего целого числа;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3356e53",
   "metadata": {},
   "source": [
    "### Часть 4\n",
    "\n",
    "Удалите все строки, в которых осталось больше одного пропуска. Если вы все сделали правильно, после этого действия в таблице не должно остаться пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca44237",
   "metadata": {},
   "source": [
    "### Часть 5\n",
    "\n",
    "Определите название города, из которого отправилось больше всего пассажиров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ee762",
   "metadata": {},
   "source": [
    "### Часть 6\n",
    "\n",
    "Определите процент выживших пассажиров от числа пассажиров, оставшихся в таблице после очистки данных. Ответ округлите до 2 знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfeb7d8",
   "metadata": {},
   "source": [
    "### Часть 7\n",
    "\n",
    "Определите число выживших пассажиров для каждого пункта отправления. В ответе должен получиться объект типа `pd.Series`, индексы которого - названия пунктов отправления, а значения - число выживших пассажиров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f70ba8",
   "metadata": {},
   "source": [
    "### Часть 8\n",
    "\n",
    "Определите процент выживших пассажиров в каждом классе. Значения округлите до 2 знаков после запятой. В ответе должен получиться объект типа `pd.Series`, индексы которого - названия классов, а значения - процент выживших пассажиров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34daca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11feaf86",
   "metadata": {},
   "source": [
    "### Часть 9\n",
    "\n",
    "Будем считать, что пассажиры, купившие билет **НЕ МЕНЕЕ** чем за $100, считаются богатыми. Определите процент выживших среди богатых пассажиров. Ответ округлите до 2 знаков после запятой. В ответе должно получиться число. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f608e1",
   "metadata": {},
   "source": [
    "### Часть 10\n",
    "\n",
    "Определите количество детей, путешествовавших в одиночку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480352b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac62cfd",
   "metadata": {},
   "source": [
    "Какие выводы вы можете сделать о выживших пассажирах Титаника? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d07cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
